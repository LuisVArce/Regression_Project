{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510c1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "from env import user, password, host\n",
    "\n",
    "def get_db_url(database):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{database}'\n",
    "\n",
    "\"\"\"\n",
    "USAGE: \n",
    "Use `from wrangle import wrangle_zillow` at the top of your notebook.\n",
    "This \n",
    "\"\"\"\n",
    "def get_zillow():\n",
    "    \"\"\"Seeks to read the cached zillow.csv first \"\"\"\n",
    "    filename = \"zillow.csv\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename)\n",
    "    else:\n",
    "        return get_new_zillow_data()\n",
    "\n",
    "def get_new_zillow_data():\n",
    "    \"\"\"Returns a dataframe of all 2017 properties that are Single Family Residential\"\"\"\n",
    "\n",
    "    sql = \"\"\"\n",
    "    select \n",
    "    bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, taxvaluedollarcnt, yearbuilt, taxamount, fips\n",
    "    from properties_2017\n",
    "    join propertylandusetype using (propertylandusetypeid)\n",
    "    where propertylandusedesc = \"Single Family Residential\"\n",
    "    \"\"\"\n",
    "    return pd.read_sql(sql, get_db_url(\"zillow\"))\n",
    "\n",
    "\n",
    "def handle_nulls(df):    \n",
    "    # We keep 99.41% of the data after dropping nulls\n",
    "    # round(df.dropna().shape[0] / df.shape[0], 4) returned .9941\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_types(df):\n",
    "    # Convert some columns to integers\n",
    "    # fips, yearbuilt, and bedrooms can be integers\n",
    "    df[\"fips\"] = df[\"fips\"].astype(int)\n",
    "    df[\"yearbuilt\"] = df[\"yearbuilt\"].astype(int)\n",
    "    df[\"bedroomcnt\"] = df[\"bedroomcnt\"].astype(int)    \n",
    "    df[\"taxvaluedollarcnt\"] = df[\"taxvaluedollarcnt\"].astype(int)\n",
    "    df[\"calculatedfinishedsquarefeet\"] = df[\"calculatedfinishedsquarefeet\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def handle_outliers(df):\n",
    "    \"\"\"Manually handle outliers that do not represent properties likely for 99% of buyers and zillow visitors\"\"\"\n",
    "    df = df[df.bathroomcnt <= 6]\n",
    "    \n",
    "    df = df[df.bedroomcnt <= 6]\n",
    "    \n",
    "    df = df[df.calculatedfinishedsquarefeet < 8000]\n",
    "    \n",
    "    df = df[df.taxvaluedollarcnt < 1000000]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def wrangle_zillow():\n",
    "    \"\"\"\n",
    "    Acquires Zillow data\n",
    "    Handles nulls\n",
    "    optimizes or fixes data types\n",
    "    handles outliers w/ manual logic\n",
    "    returns a clean dataframe\n",
    "    \"\"\"\n",
    "    df = get_zillow_data()\n",
    "\n",
    "    df = handle_nulls(df)\n",
    "\n",
    "    df = optimize_types(df)\n",
    "\n",
    "    df = handle_outliers(df)\n",
    "\n",
    "    df.to_csv(\"zillow.csv\", index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the baseline residual error (actual - baseline prediction)\n",
    "\n",
    "# Residuals are the difference between goal and prediction I have\n",
    "\n",
    "#lm_df[\"baseline_residuals\"] = lm_df[\"home_value\"] - lm_df[\"baseline\"]\n",
    "#lm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lm_df[\"residuals\"] = lm_df[\"home_value\"] - lm_df[\"predictions\"]\n",
    "#lm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d8abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering creating a function that creates these plots\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "ax = sns.scatterplot(x = \"finished_sq_feet\", y = \"baseline_residuals\", data = rmse_validate.sample(1000, random_state = 123))\n",
    "plt.axhline(y = 0, ls = ':', color = \"red\")\n",
    "plt.xlabel('x_variable')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('Baseline Residuals')\n",
    " # removing axes scientific notation\n",
    "plt.ticklabel_format(style = \"plain\")\n",
    "\n",
    "# making individual plots more readable\n",
    "ax.figure.set_size_inches(18, 6)\n",
    "\n",
    "plt.subplot(122)\n",
    "ax = sns.scatterplot(x = \"finished_sq_feet\", y = \"residuals\", data = lm_df.sample(1000, random_state = 123))\n",
    "plt.axhline(y = 0, ls = ':', color = \"red\")\n",
    "\n",
    "plt.xlabel('x_variable')\n",
    "plt.ylabel('Residual')\n",
    "plt.title('OLS Model Residuals')\n",
    "# removing axes scientific notation\n",
    "plt.ticklabel_format(style = \"plain\") \n",
    "\n",
    "# making individual plots more readable\n",
    "ax.figure.set_size_inches(18, 8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the Sum of Squared Errors \"SSE\" or \"Residual Sum of Squares\"/RSS for my model\n",
    "# where the Sum of Squared Errors or Residual Sum of Squares refers to the total \"dispersion\" of the individual data point error\n",
    "# this measurement can determine how well or not the created model represents the \"actual\" target data\n",
    "\n",
    "lm_df[\"residual^2\"] = lm_df[\"residuals\"].round(2) ** 2\n",
    "lm_df[\"baseline_residual^2\"] = lm_df[\"baseline_residuals\"].round(2) ** 2\n",
    "lm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08302180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating sum of squared error\n",
    "\n",
    "SSE_model = sum(lm_df[\"residual^2\"])\n",
    "print('(Model) SSE = {:.1f}'.format(SSE_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf38d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the explained sum of squares or \"ESS\"\n",
    "# explained error\n",
    "# The ESS (Explained Sum of Squares) is the sum of the difference between each predicted value (y_hat = home_price prediction) and the mean of all actual values (y.mean = home_value mean)\n",
    "\n",
    "ESS_model = sum((lm_df[\"predictions\"] - lm_df[\"home_value\"].mean()) ** 2)\n",
    "print('(Model) Explained Sum of Squares = {:.1f}'.format(ESS_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d016cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total sum of squares errors or \"TSS\"\n",
    "# The TSS (Total Sum of Squares) is the sum of difference between the actual final grade and the mean of all final grades\n",
    "# It can also be derived by summing the ESS and SSE\n",
    "\n",
    "TSS_model = ESS_model + SSE_model\n",
    "print('(Model) Total Sum of Squares = {:.1f}'.format(TSS_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean squared error or MSE\n",
    "# we arrive at this by dividing your SSE by the total number of data points\n",
    "# i.e. the average of your errors that have each been squared\n",
    "\n",
    "MSE_model = SSE_model/len(lm_df)\n",
    "print('(Model) Mean Squared Error = {:.1f}'.format(MSE_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the root mean squared error or RMSE\n",
    "\n",
    "RMSE_model = sqrt(MSE_model)\n",
    "print('(Model) Root Mean Squared Error = {:.1f}'.format(RMSE_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1e6b4",
   "metadata": {},
   "source": [
    "#### Calculate the sum of squared errors, mean squared error, and root mean squared error for the baseline model (i.e. a model that always predicts the average home_value amount / or \"baseline_predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ed9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating sum of squared error\n",
    "\n",
    "SSE_baseline = sum(lm_df[\"baseline_residual^2\"])\n",
    "print('(Baseline) SSE = {:.1f}'.format(SSE_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the explained sum of squares or \"ESS\"\n",
    "# explained error\n",
    "# The ESS (Explained Sum of Squares) is the sum of the difference between each predicted value (y_hat = home_price prediction) and the mean of all actual values (y.mean = home_value mean)\n",
    "\n",
    "ESS_baseline = sum((lm_df[\"baseline\"] - lm_df[\"home_value\"].mean()) ** 2)\n",
    "print('(Baseline) Explained Sum of Squares = {:.1f}'.format(ESS_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the total sum of squares errors or \"TSS\"\n",
    "# The TSS (Total Sum of Squares) is the sum of difference between the actual final grade and the mean of all final grades\n",
    "# It can also be derived by summing the ESS and SSE\n",
    "\n",
    "TSS_baseline = ESS_baseline + SSE_baseline\n",
    "print('(Baseline) Total Sum of Squares = {:.1f}'.format(TSS_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mean squared error or MSE\n",
    "# we arrive at this by dividing your SSE by the total number of data points\n",
    "# i.e. the average of your errors that have each been squared\n",
    "\n",
    "MSE_baseline = SSE_baseline/len(lm_df)\n",
    "print('(Baseline) Mean Squared Error = {:.1f}'.format(MSE_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd0b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the root mean squared error or RMSE\n",
    "\n",
    "RMSE_baseline = sqrt(MSE_baseline)\n",
    "print('(Baseline) Root Mean Squared Error = {:.1f}'.format(RMSE_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa9fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating model variance\n",
    "# where variance == R^2 or \"coefficient of determination\" (a measurement from 0 to 1)\n",
    "# R2: variance in y (target) explained by X (predictor); closer to 1 is better\n",
    "\n",
    "model_variance = ESS_model/TSS_model\n",
    "print('Model Variance = {:.1f}'.format(model_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the baseline variance\n",
    "\n",
    "baseline_variance = ESS_baseline/TSS_baseline\n",
    "print('Baseline Variance = {:.1f}'.format(baseline_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90913c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use sklearn to calculate model variance\n",
    "\n",
    "model_var = sklearn.metrics.explained_variance_score(lm_df[\"home_value\"], lm_df[\"predictions\"])\n",
    "model_var.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf97855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use sklearn to calculate baseline variance\n",
    "\n",
    "baseline_var = sklearn.metrics.explained_variance_score(lm_df[\"home_value\"], lm_df[\"baseline\"])\n",
    "baseline_var.round(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This model performs 33% better than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sum_of_squares(SSE_baseline, SSE_model):\n",
    "    if SSE_model >= SSE_baseline:\n",
    "        print(\"Model ain't cutting it\")\n",
    "    else:\n",
    "        print(\"Model outperforms baseline!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67dbc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write python code that compares the sum of squared errors for your model against the sum of squared errors for the baseline model and outputs whether or not your model performs better than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### What is the amount of variance explained in your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot residuals for the linear regression model that you made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68d290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201c5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
